{"name":"benchETLGFS","components":{"SenMLParse.js":{"code_name":"SenMLParse.js","source":" /* \n * SenMLParse file adapted from RIoTBench (SenMLParse.java)\n */\n\n//var things = require('things-js');\nvar things = require('things-js')\n\n\n/* configurable variables */\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/SenMLSpout';\nvar publish_topic = 'thingsjs/IoTBench/SenMLParse';\n\nvar pubsub = new things.Pubsub(pubsub_url);\n// mkdir RIOT/ETL folder if not exist \n// save file inside \nfunction processMessage(data) {\n\tvar line = data.toString();\n\t\n\t// Remove everything before first { -- dunno why the data is made like that\n\tvar trimmedLine = line.substr(line.indexOf('{'));\n\t\n\t// JSON-parse object\n\tvar obj = JSON.parse(trimmedLine);\n\t//console.log(obj);\n\t\n\t// What follows is derived from the logic in SenMLParse\n\t// Ensuring compatibility as much as possible so that we can properly\n\t// implement / port the next \"steps\".\n\tvar baseTime = 'bt' in obj ? obj['bt'] : 0;\n\tvar baseUnit = 'bu' in obj ? obj['bu'] : \"\";\n\tvar baseName = 'bn' in obj ? obj['bn'] : \"\";\n\tvar jsonArr = obj['e'];\n\t\n\tvar v,n,u,t;\n\t\n\tvar mapkeyvalues = {};\n\t\n\t//console.log(jsonArr);\n\t\n\tfor (var j=0; j<jsonArr.length; j++) {\n\t\tvar jsonObject = jsonArr[j];\n\t\t//console.log(jsonObject);\n\n\t\tv = 'v' in jsonObject ? jsonObject['v'] : jsonObject['sv'];\n\t\tt = 'v' in jsonObject ? jsonObject['t'] : 0;\n\t\tt += baseTime;\n\n\t\t/* if name does not exist, consider base name */\n\t\tn = 'n' in jsonObject ? jsonObject['n'] : baseName;\n\t\tu = 'u' in jsonObject ? jsonObject['u'] : baseUnit;\n\n\t\tmapkeyvalues[n] = v;\n\t}\n\t\n\t\n\t// Publish the output\n// \tconsole.log(mapkeyvalues);\n    pubsub.publish(publish_topic, mapkeyvalues);\n}\n\n/* Connect pubsub */\npubsub.on('ready', function(){\n    \n\t// Subscribe to spout publications\n\tpubsub.subscribe(pubsub_topic, processMessage);\n});\n","count":1,"required_memory":1},"SenMLSpout.js":{"code_name":"SenMLSpout.js","source":"/* \n * Publishes SenML data over pub sub\n */\n\n//var things = require('things-js');\nvar things = require('things-js');\nvar readline = require('readline');\n\n/* configurable variables */\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/SenMLSpout';\nvar publish_interval = 1000;\n\nvar pubsub = new things.Pubsub(pubsub_url);\n\n/* SenML Lines */\nvar lines = [];\nvar currentLine = 0;\n\nfunction startSpout() {\n\tvar lineReader = readline.createInterface({\n\t\tinput: require('fs').createReadStream('TAXI_sample_data_senml.csv')\n\t});\n\n\tlineReader.on('line', function (line) {\n\t\t//console.log('Line from file:', line);\n\t\tlines.push(line);\n\t});\n\n\tlineReader.on('close', function() {\n\t\t// File ended\n\t\tconsole.log('Done reading file... Starting to publish');\n\t\tsetInterval(publishLine, publish_interval);\n\t});\t\n}\n\n/* Publish a SenML line */\nfunction publishLine() {\n\t// For the moment, publish as a raw string rather than json-serializing\n\t// since de-jsoning will be performed by the next 'bolt'\n\tif (currentLine >= lines.length) {\n\t\t/*\n\t\tconsole.log(\"Done sending data.\");\n\t\treturn;\n\t\t*/\n\t   currentLine = 0;\n\t}\n\tconsole.log(\"Publishing line \" + currentLine);\n\tpubsub.publish(pubsub_topic, lines[currentLine]);\n\tcurrentLine++;\n}\n\npubsub.on('ready', function(){\n    console.log(\"Beginning spout\");\n    startSpout();\n});\n\n","count":1,"required_memory":1},"Annotate.js":{"code_name":"Annotate.js","source":"var things = require('things-js');\nvar fs = require('fs');\nvar readline = require('readline');\nvar mongoUrl = 'mongodb://localhost:27017/things-js-fs';\nvar GFS = require('things-js').addons.gfs(mongoUrl);\n\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/ETL/Interpolation';\nvar publish_topic = 'thingsjs/IoTBench/ETL/Annotate';\n\nvar pubsub = new things.Pubsub(pubsub_url);\n\n/* annotation properties */\nvar useMsgField, filePath, schemaTypes;\nvar annotationMap = {};\n\nfunction setup() {\n    var args = process.argv.slice(2);\n    var properties;\n    var schemaPath;\n    var x, y;\n\n    // default to TAXI property set if no specific property file is given\n\n    if (!args.length) {\n        args = ['./TAXI_properties.json'];\n    }\n    GFS.readFile(args[0], function(err2, data) {\n        if (err2) {\n            console.log('\\x1b[44m%s\\x1b[0m', 'Couldn\\'t fetch properties: ' + err2);\n            process.exit();\n        }\n        properties = JSON.parse(data);\n        useMsgField = properties['ANNOTATE.ANNOTATE_MSG_USE_FIELD'] || 0;\n        filePath = properties['ANNOTATE.ANNOTATE_FILE_PATH'];\n        schemaPath = properties['ANNOTATE.ANNOTATE_SCHEMA'];\n\n        GFS.readFile(schemaPath, function(err3, data1) {\n        \t// console.log(\"lalala\"+data1);\n            schemaTypes = data1.toString();\n            GFS.readFile(filePath, function(err4, data2) {\n            \t// console.log(\"bababa\"+data2);\n                var premap = data2.toString().split('\\n');\n\n                premap.forEach(function(line) {\n                    var token = line.split(':');\n                    annotationMap[token[0]] = token[1];\n                });\n                console.log('Beginning annotation'+annotationMap.toString());\n                pubsub.subscribe(pubsub_topic, annotate);\n            });\n        });\n    });\n}\n// var x = new Promise(function(resolve){\n// \treadSchemaTypes(schemaPath).then(function(data){\n// \t\tschemaTypes = data;\n// \t\tresolve();\n// \t});\n// });\n// var y = createAnnotationMap(filePath);\n\n// return Promise.all([x,y]);\n\n\n// function readSchemaTypes(file){\n// \tvar lineReader;\n// \treturn new Promise(function(resolve, reject){\n// \t\ttry{\n// \t\t\tlineReader = readline.createInterface({\n// \t\t\t\tinput: fs.createReadStream(file)\n// \t\t\t});\n// \t\t}\n// \t\tcatch(e){\n// \t\t\tconsole.log('Problem reading schema: ' + e);\n// \t\t\tprocess.exit();\n// \t\t}\n// \t\tlineReader.on('line', function(line){\n// \t\t\tresolve(line);\n// \t\t});\n// \t});\n// }\n\n// function createAnnotationMap(file){\n// \tvar lineReader;\n\n// \treturn new Promise(function(resolve, reject){\n// \t\ttry{\n// \t\t\tlineReader = readline.createInterface({\n// \t\t\t\tinput: fs.createReadStream(file)\n// \t\t\t});\n// \t\t}\n// \t\tcatch(e){\n// \t\t\tconsole.log('Could not create annotation map: ' + e);\n// \t\t\tprocess.exit();\n// \t\t}\n// \t\tlineReader.on('line', function(line){\n// \t\t\tvar token = line.split(':');\n// \t\t\tif(token[0] && token[1]){\n// \t\t\t\tannotationMap[token[0]] = token[1];\n// \t\t\t}\n// \t\t});\n// \t\tlineReader.on('close', function(){\n// \t\t\tconsole.log('Completed annotation map from file');\n// \t\t\tresolve();\n// \t\t});\n// \t});\n// }\n\nfunction annotate(data) {\n    // get the annotation key\n    var keys = Object.keys(data);\n    var field = keys[useMsgField];\n    var fieldValue = data[field];\n    var annotateValue = annotationMap[fieldValue];\n\n    if (annotateValue) {\n        parsedFields = annotateValue.split(',');\n        // get the missing field names\n        var schemaArr = schemaTypes.split(',');\n        schemaArr = schemaArr.slice(keys.length + 1, schemaArr.length);\n\n        for (var i = 0; i < parsedFields.length; i++) {\n            var fieldName = schemaArr[i];\n            data[fieldName] = parsedFields[i];\n        }\n        console.log('Made annotations to data');\n        console.log(schemaArr, parsedFields);\n        console.log('\\n');\n    }\n    console.log('Publishing annotate');\n    pubsub.publish(publish_topic, data);\n}\n\npubsub.on('ready', function() {\n    setup();\n});","count":1,"required_memory":1},"BloomFilterCheck.js":{"code_name":"BloomFilterCheck.js","source":"var things = require('things-js');\nvar bloom = require('bloomfilter').BloomFilter;\nvar fs = require('fs');\nvar mongoUrl = 'mongodb://localhost:27017/things-js-fs';\nvar GFS = require('things-js').addons.gfs(mongoUrl);\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/ETL/RangeFilterCheck';\nvar publish_topic = 'thingsjs/IoTBench/ETL/BloomFilterCheck';\nvar model = [34263556, 142119048, 809554946, 67321864, -1073151776, 180220686, -1055686623, -1811897856, 184864902, 674317344, -2095042559, 289689626, -518930432, 157291776, 599807120, 428376870, 33624352, 270090256, 86310996, -931064831, 272646273, 563217941, -2129490875, 136987648, -801636288, 335553056, 1346914320, -976889591, 1430801504, -1441791912];\n\n/* bloom filter properties */\nvar DEFAULT_FALSEPOSITIVE = 0.1;\nvar DEFAULT_INSERTIONS = 20000000\nvar bloomFilter, testingRange, useMsgField;\n\nvar pubsub = new things.Pubsub(pubsub_url);\n\nfunction getFilterSize(n, fpp) {\n    return (-1) * Math.ceil((n * Math.log(fpp)) / Math.pow(Math.log(2), 2));\n}\n\nfunction getNumHashes(m, n) {\n    return Math.ceil((m / n) * Math.log(2));\n}\n\nfunction createBloomFilter() {\n    var args = process.argv.slice(2);\n    var properties;\n\n    // default to TAXI property set if no specific property file is given\n    if (!args.length) {\n        args = ['./TAXI_properties.json'];\n    }\n    GFS.readFile(args[0], function(err2, data) {\n        if (err2) {\n            console.log('\\x1b[44m%s\\x1b[0m', 'Couldn\\'t fetch properties: ' + err2);\n            process.exit();\n        }\n        properties = JSON.parse(data);\n        useMsgField = properties['BLOOMFILTER.USE_MSG_FIELD'] || 0;\n        testingRange = properties['BLOOMFILTER.EXPECTED_INSERTIONS'] || DEFAULT_INSERTIONS\n        var m = getFilterSize(testingRange, properties['BLOOMFILTER.FALSEPOSITIVE_RATIO'] || DEFAULT_FALSEPOSITIVE);\n        var k = getNumHashes(m, testingRange);\n\n        try {\n            bloomFilter = new bloom(model, k);\n            console.log('Beginning bloom filter');\n            pubsub.subscribe(pubsub_topic, doBloomFilter);\n        } catch (c) {\n            console.log('A problem occured: ' + c);\n            process.exit();\n        }\n    });\n}\n\nfunction doBloomFilter(data) {\n    var value;\n    // if user specified they want to use a specific field value\n    if (useMsgField > 0) {\n        var keys = Object.keys(data);\n        value = data[keys[useMsgField - 1]];\n    } else {\n        // generate a random value between 0 - testingRange\n        value = Math.floor(Math.random() * testingRange + 1);\n    }\n    var res = bloomFilter.test(String(value));\n    console.log('Bloom filter tested: ' + res);\n    if (res ) {\n        console.log(\"PASS BLOOMING\");\n        pubsub.publish(publish_topic, data);\n    }\n}\n\npubsub.on('ready', function() {\n    createBloomFilter();\n});","count":1,"required_memory":1},"CsvToSenML.js":{"code_name":"CsvToSenML.js","source":"var things = require('things-js');\nvar fs = require('fs');\nvar readline = require('readline');\nvar mongoUrl = 'mongodb://localhost:27017/things-js-fs';\nvar GFS = require('things-js').addons.gfs(mongoUrl);\n\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/ETL/Annotate';\nvar publish_topic = 'thingsjs/IoTBench/ETL/CsvToSenML';\n\nvar pubsub = new things.Pubsub(pubsub_url);\n\n/* csv to senml properties */\nvar schemaFields = {};\nvar schemaTypes = [];\nvar schemaValues = [];\n\nfunction setup() {\n    var args = process.argv.slice(2);\n    var properties;\n    var schemaFile;\n\n    // default to TAXI property set if no specific property file is given\n    if (!args.length) {\n        args = ['./TAXI_properties.json'];\n    }\n\n    GFS.readFile(args[0], function(err2, data) {\n        if (err2) {\n            console.log('\\x1b[44m%s\\x1b[0m', 'Couldn\\'t fetch properties: ' + err2);\n            process.exit();\n        }\n        properties = JSON.parse(data);\n        schemaFile = properties['PARSE.CSV_SCHEMA_WITH_ANNOTATEDFIELDS_FILEPATH'];\n        if (!schemaFile) {\n            console.log('Schema file does not exist');\n            process.exit();\n        }\n        GFS.readFile(schemaFile, function(err3, data2) {\n            // console.log(\"bababa\"+data2);\n            var premap = data2.toString().split('\\n');\n            // line1\n            var fields = premap[0].split(',');\n            var i = 0;\n            fields.forEach(function(field) {\n                schemaFields[field] = i;\n                i++;\n            });\n            // line2\n            schemaTypes = premap[1].split(',');\n\n            // line3\n            schemaValues = premap[2].split(',');\n            console.log('Beginning conversion to SenML format');\n            pubsub.subscribe(pubsub_topic, convertToSenML);\n        });\n        // return parseEntireSchema(schemaFile);\n        // parseEntireSchema(schemaFile).then(function(){\n\n        // }\n    });\n}\n\n// function parseEntireSchema(file){\n// \tvar lineNumber = 0;\n// \tvar lineReader;\n\n// \treturn new Promise(function(resolve, reject){\n// \t\ttry{\n// \t\t\tlineReader = readline.createInterface({\n// \t\t\t\tinput: fs.createReadStream(file)\n// \t\t\t});\n// \t\t}\n// \t\tcatch(e){\n// \t\t\tconsole.log('Problem reading schema: ' + e);\n// \t\t\tprocess.exit();\n// \t\t}\n// \t\tlineReader.on('line', function(line){\n// \t\t\tswitch(lineNumber){\n// \t\t\t\tcase 0: \n// \t\t\t\t\tvar fields = line.split(',');\n// \t\t\t\t\tvar i = 0;\n// \t\t\t\t\tfields.forEach(function(field){\n// \t\t\t\t\t\tschemaFields[field] = i;\n// \t\t\t\t\t\ti++;\n// \t\t\t\t\t});\n// \t\t\t\t\tbreak;\n// \t\t\t\tcase 1:\n// \t\t\t\t\tschemaTypes = line.split(',');\n// \t\t\t\t\tbreak;\n// \t\t\t\tcase 2:\n// \t\t\t\t\tschemaValues = line.split(',');\n// \t\t\t\t\tbreak;\n// \t\t\t}\n// \t\t\tlineNumber++;\n// \t\t});\n// \t\tlineReader.on('close', function(){\n// \t\t\tresolve();\n// \t\t});\n// \t});\n// }\n\nfunction convertToSenML(data) {\n    var arr = [];\n    var keys = Object.keys(data);\n\n    keys.forEach(function(field) {\n        var senml = {};\n        senml[\"n\"] = field;\n        var index = schemaFields[field];\n        var type = schemaTypes[index];\n        var val = schemaValues[index];\n\n        senml[\"u\"] = type;\n        senml[val] = data[field];\n\n        arr.push(senml);\n    });\n    console.log(JSON.stringify(arr));\n    pubsub.publish(publish_topic, JSON.stringify({ \"e\": arr }));\n}\n\npubsub.on('ready', function() {\n    setup();\n});","count":1,"required_memory":1},"Interpolation.js":{"code_name":"Interpolation.js","source":"var things = require('things-js');\nvar fs = require('fs');\nvar mongoUrl = 'mongodb://localhost:27017/things-js-fs';\nvar GFS = require('things-js').addons.gfs(mongoUrl);\n\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/ETL/BloomFilterCheck';\nvar publish_topic = 'thingsjs/IoTBench/ETL/Interpolation';\n\nvar pubsub = new things.Pubsub(pubsub_url);\n\n/* interpolation properties */\nvar ID = 'ID';\nvar USE_MSG_FIELD_LIST, WINDOW_SIZE;\nvar valuesMap = {};\n\n// mkdir RIOT/ETL folder if not exist \n// save file inside \nfunction setup() {\n    var args = process.argv.slice(2);\n    var properties;\n\n    // default to TAXI property set if no specific property file is given\n    if (!args.length) {\n        args = ['./TAXI_properties.json'];\n    }\n\n    GFS.readFile(args[0], function(err2, data){\n        if (err2) {\n            console.log('\\x1b[44m%s\\x1b[0m', 'Couldn\\'t fetch properties: ' + err2);\n            process.exit();\n        }\n        properties = JSON.parse(data);\n        USE_MSG_FIELD_LIST = properties['INTERPOLATION.USE_MSG_FIELD_LIST'];\n        WINDOW_SIZE = properties['INTERPOLATION.WINDOW_SIZE'] || 0;\n        if (!USE_MSG_FIELD_LIST) {\n            console.log('No fields to interpolate');\n            process.exit();\n        }\n\t    console.log('Beginning Interpolation');\n\t    pubsub.subscribe(pubsub_topic, interpolate);\n    });\n}\n\nfunction interpolate(data) {\n    console.log(\"START INTERPOLATION!!!!\");\n\n    if (WINDOW_SIZE == 0) {\n        // do nothing with the data\n        console.log('No interpolation needed. Publishing data');\n        pubsub.publish(publish_topic, data);\n        return;\n    }\n\n    USE_MSG_FIELD_LIST.forEach(function(field) {\n        var key = ID + field;\n\n        if (field in data) {\n\n            if (key in valuesMap) {\n                if (data[field] === null) {\n                    var count = 0;\n                    valuesMap[key].forEach(function(val) {\n                        count += val;\n                    });\n                    var newValue = (count) / (valuesMap[key].length);\n                    console.log('Interpolated field ' + field + 'with new value: ' + newValue);\n                    data[field] = newValue;\n                } else {\n                    // add the new data in\n                    if (valuesMap[key].length === WINDOW_SIZE) {\n                        valuesMap.splice(0, 1);\n                    }\n                    valuesMap[key].push(data[field]);\n                }\n            } else if (data[field] !== null) {\n                valuesMap[key] = [data[Field]];\n            }\n        }\n    });\n    pubsub.publish(publish_topic, data);\n}\n\npubsub.on('ready', function() {\n    setup();\n});","count":1,"required_memory":1},"RangeFilterCheck.js":{"code_name":"RangeFilterCheck.js","source":"/*\n * Publishes filtered SenML data (already parsed) over pub sub\n */\nvar things = require('things-js');\nvar fs = require('fs');\nvar mongoUrl = 'mongodb://localhost:27017/things-js-fs';\nvar GFS = require('things-js').addons.gfs(mongoUrl);\n\nvar pubsub_url = 'mqtt://localhost';\nvar pubsub_topic = 'thingsjs/IoTBench/SenMLParse';\nvar publish_topic = 'thingsjs/IoTBench/ETL/RangeFilterCheck';\n\nvar pubsub = new things.Pubsub(pubsub_url);\n\n/* range filter definitions */\nvar ranges = {};\n\nfunction MinMax(min, max){\n\tthis.min = min;\n\tthis.max = max;\n}\n// mkdir RIOT/ETL folder if not exist \n// save file inside \nfunction getRange(){\n\tvar args = process.argv.slice(2);\n\n\t// default to TAXI property set if no specific property file is given\n\tif(!args.length){\n\t\targs = ['./TAXI_properties.json'];\n\t}\n\n\t\t  GFS.readFile(args[0], function(err2, data){\n\t   \t\tif (err2) {\n            console.log('\\x1b[44m%s\\x1b[0m', 'Couldn\\'t fetch properties: ' + err2);\n            process.exit();\n        \t}\n\t \t\tproperties = JSON.parse(data);\n\t \t\tvar validRanges = properties['FILTER.RANGE_FILTER.VALID_RANGE'];\n\t\t\tfor(field in validRanges){\n\t\t\tvar tokens = validRanges[field].split(':');\n\t\t\ttry{\n\t\t\t\tvar rng = new MinMax(parseFloat(tokens[0]), parseFloat(tokens[1]));\n\t\t\t\tranges[field] = rng;\n\t\t\t}\n\t\t\tcatch(c){\n\t\t\t\tconsole.log('Error parsing value: ' + c);\n\t\t\t\tprocess.exit();\n\t\t\t\t}\n\t\t\t}\n\t\t\tconsole.log('Beginning range filter');\n    \t\tpubsub.subscribe(pubsub_topic, checkRange);\n\t\t});\t\t\n}\n\nfunction checkRange(data){\n\tvar success = true;\n\tfor(field in ranges){\n\t\tif(field in data){\n\t\t\tif( (data[field] > ranges[field].max) || (data[field] < ranges[field].min) ){\n\t\t\t\tsuccess = false;\n\t\t\t}\n\t\t}\n\t}\n\tif(success){\n\t\tconsole.log('Data met the range criteria');\n\t\tpubsub.publish(publish_topic, data);\n\t}\n}\n\n\npubsub.on('ready', function(){\n\tgetRange();\n});\n","count":1,"required_memory":1}}}